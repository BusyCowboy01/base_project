server.port=8081
#通过触发器，去控制什么时候进行热加载部署新的文件
#spring.devtools.restart.trigger-file=.trigger
#指定某些文件不进行监听，即不会进行热加载
#spring.devtools.restart.exclude=application.properties

#============================文件上传==========================
#图片上传配置
web.upload-path=C:/Users/18045050/Desktop/
spring.resources.static-locations=classpath:/META-INF/resources/,classpath:/resources/,classpath:/static/,file:${web.upload-path}

#===========================mybatis配置=====================
spring.datasource.url=jdbc:mysql://localhost:3306/test?useUnicode=true&characterEncoding=utf-8
spring.datasource.username =root
spring.datasource.password =root
#使用阿里巴巴druid数据源，默认使用自带的
spring.datasource.type =com.alibaba.druid.pool.DruidDataSource
#开启控制台打印sql
mybatis.configuration.log-impl=org.apache.ibatis.logging.stdout.StdOutImpl
mybatis.mapper-locations=classpath:mapper/*.xml

#==============================redis配置====================
spring.redis.database=0
spring.redis.host=127.0.0.1
spring.redis.port=6379
# 连接超时时间 单位 ms（毫秒）
spring.redis.timeout=3000
# 连接池中的最大空闲连接，默认值也是8。
spring.redis.jedis.pool.max-idle=200
#连接池中的最小空闲连接，默认值也是0。
spring.redis.jedis.pool.min-idle=200
# 如果赋值为-1，则表示不限制；pool已经分配了maxActive个jedis实例，则此时pool的状态为exhausted(耗尽)。
spring.redis.jedis.pool.max-active=2000
# 等待可用连接的最大时间，单位毫秒，默认值为-1，表示永不超时
spring.redis.jedis.pool.max-wait=2000

#=============================整合active mq==================================
#整合jms测试，安装在别的机器，防火墙和端口号记得开放
spring.activemq.broker-url=tcp://127.0.0.1:61616
#集群配置
#spring.activemq.broker-url=failover:(tcp://localhost:61616,tcp://localhost:61617)
spring.activemq.user=admin
spring.activemq.password=admin
#下列配置要增加依赖
spring.activemq.pool.enabled=true
spring.activemq.pool.max-connections=100

#=============================kafka相关配置==========================
spring.kafka.consumer.bootstrap-servers==127.0.0.1:9092
spring.kafka.consumer.enable-auto-commit=true
spring.kafka.consumer.auto-commit-interval=100
spring.kafka.consumer.auto-offset-reset=latest
spring.kafka.consumer.group-id=kafka-test-group
# 指定消息key和消息体的编解码方式
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer

spring.kafka.producer.bootstrap-servers=127.0.0.1:9092
spring.kafka.producer.retries=1
spring.kafka.producer.batch-size=4096
spring.kafka.producer.buffer-memory=40960
# 指定消息key和消息体的编解码方式
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer

#================================ES搜索配置===================================
spring.data.elasticsearch.cluster-name=elasticsearch
spring.data.elasticsearch.cluster-nodes=127.0.0.1:9300
spring.data.elasticsearch.repositories.enabled=true




